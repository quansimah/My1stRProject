# add debt service data to debt.clean
debt.clean$debt.service.cap <- c(dsc.2009,dsc.2014,dsc.2019)
# set column names
colnames(debt.clean) <- c("country.name", "years", "financial.integration",
"debt.stock", "debt.service.cap")
# write debt.clean as a csv in path.data.clean
write.csv(debt.clean, paste(path.data.clean,"debt.clean.csv", sep = ""),
row.names = FALSE)
# make data set that drops data with NA financial integration
debt.new <- debt.clean[complete.cases(debt.clean),]
# write a new csv with complete data
write.csv(debt.new, paste(path.data.clean,"debt.complete.csv", sep = ""),
row.names = FALSE)
# ==============================================================================
# =============================================================================
#
# MAIN
#
R.version.string
#   "R version 4.0.3 (2020-10-10)"
#
# =============================================================================
# NOTES
# open the scripts in the orders in which they are numbered.
# - "2.simulation.R" shows how the data used for the analyses was simulated
# - "3.simple.linear.regression.R" shows the processes involved in conducting
# a simple linear regression
# - "4.assumptions.R" explores the assumptions of a linear regression
# - "5.multiple.regression.R" shows the processes for a multiple linear
# regresssion
# - "6.data.manipulation.R" shows how the debt data obtained from the World Bank
# was cleaned
# - "7.data.analysis.R" shows the attempts at analysing the clean debt data
# - "8.saveplots.R" is a script where plots were saved into pdf's
# =============================================================================
# Set the working dir to retrace where files should be
# in case the code fails
wk.dir <- getwd() #
# =============================================================================
# ---- libraries ----
# install libraries needed for the project
# load the libraries needed for the project to run
library(mvtnorm)
library(e1071)
library(lattice)
library(DAAG)
library(ggplot2)
library(DataCombine)
library(gvlma)
library(AER)
library(MASS)
library(corrplot)
# =============================================================================
# --- folder management ---
# names of project folders ("figures", "data.raw","data.clean","results")
# store names of the folders in an object
folder.names <- c("1.data.raw","2.data.clean", "3.results","4.figures")
# make the folders if they don't exist yet.
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
#Store in an object the file path to these folders so we can
# read from them and write to them.
path.data.raw <- paste(wk.dir, "/", folder.names[1], "/", sep = "")
path.data.clean <- paste(wk.dir, "/", folder.names[2], "/", sep = "")
path.results <- paste(wk.dir, "/", folder.names[3], "/", sep = "")
path.fig <- paste(wk.dir, "/",folder.names[4], "/", sep = "")
# =============================================================================
# --- run scripts ---
# ==== end =================================================================
#
#
# SIMPLE LINEAR REGRESSION
# Carry out a simple linear regression on the simulated data
# ==== BACKGROUND =============================================================
# For the simple linear regression, we only take into account two variables
# These variables will be obtained from a previously R simulated data
# See how the simulation was carried out in the file "simulation.R"
# The variables to be considered from the dataset will be X1 and Y
# Let us consider X1 as the explanatory variable and Y as the response variable
# ==============================================================================
# ====== READ CSV ==============================================================
# read the simulated data csv and  assign to object sim.data
sim.data <- data.t <- read.csv(paste(path.data.clean,"simulated.data.csv",
sep = ""), stringsAsFactors = FALSE,
strip.white = TRUE)
# ==============================================================================
# ===== GRAPHICAL ANALYSIS =====================================================
# First, let us carry out a graphical analysis of our variables
# let us plot X1 againnst Y1 to visualize their relationship
slr.plot <- plot(x= sim.data$X1, y= sim.data$Y, main ="X1~ Y",
pch =16, col = 'red', xlab = "X1", ylab = "Y")
# do outliers affect the line in the scatter plot?
# let us check for outliers in both variables
# We want to visualize the plots of both variables side by side
# so we divide the graph area into 2 columns using par
par(mfrow = c(1,2))
# make a box plot for X1
boxplot(sim.data$X1, main = "X1",
sub = paste("Outlier rows:",
boxplot.stats(sim.data$X1)$out))
# There are no outliers for X1
# make a box plot for Y
boxplot(sim.data$Y, main = "Y",
sub = paste("Outlier rows:",
boxplot.stats(sim.data$Y)$out))
# There are no outliers for Y
# We are good to go
# Now let's find out if both variables are close to normality using density plots
# this is  done with the Rpackage e1071
# making a density plot for X1
plot(density(sim.data$X1), main = "Density Plot:X1",
ylab = "Frequency", sub = paste("Skewness:",
round(e1071::skewness(sim.data$X1),2)))
# making the polygon red
polygon(density(sim.data$X1), col = 'red')
# Skewness = 0.01
# This is a very low level of skewness
# making a density plot for Y
plot(density(sim.data$Y), main = "Density Plot:Y",
ylab = "Frequency", sub = paste("Skewness:",
round(e1071::skewness(sim.data$Y),2)))
# making the polygon red
polygon(density(sim.data$Y), col = 'red')
# Skewness = 0.18
# This is also a low level of skewness
# ==============================================================================
# ======= CORRELATION ==========================================================
# let us test for correlation between both variables
cor(sim.data$Y, sim.data$X1)
# 0.774579;  this suggests a strong positive correlation between both variables
# ==============================================================================
# ======= LINEAR MODEL =========================================================
# build a linear model
linearMod <- lm(Y ~ X1, data = sim.data)
# inspect the model
print(linearMod)
#Call:
# lm(formula = Y ~ X1, data = sim.data)
# Coefficients:
#   (Intercept)           X1
#       105.308        4.436
# This translates to Yestimate = 105.308 + 4.436*X1
# ==============================================================================
# === LINEAR REGRESSION DIAGNOSTICS ============================================
# get model summary
summary(linearMod)
#> Call:
#> lm(formula = Y ~ X1, data = sim.data)
#> Residuals:
#>   Min       1Q   Median       3Q      Max
#> -13.4182  -6.1344  -0.5484   5.7165  15.5783
#> Coefficients:
#>              Estimate Std. Error t value Pr(>|t|)
#> (Intercept) 105.3075    13.2156   7.968 2.46e-10 ***
#>  X1            4.4357     0.5179   8.564 3.13e-11 ***
#>  ---
#>   Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1
#> Residual standard error: 7.229 on 48 degrees of freedom
#> Multiple R-squared:  0.6044,	Adjusted R-squared:  0.5962
#>  F-statistic: 73.35 on 1 and 48 DF,  p-value: 3.133e-11
# The Coefficients estimates and model p-values are lower than 0.05
# This means, the model is statistically significant
# The Adjusted R-Squared shows that the model acoounts for 59.62% of the data
# ==============================================================================
# ==== T-STATISTIC AND P-VALUE =================================================
# Assessing the t-statistic, F-statistic, and p-values manually
# capture model summary as an object
modelSummary <- summary(linearMod)
# captured model coefficients as an object
modelCoeffs <- modelSummary$coefficients
# get estimates for regressor
beta.estimate <- modelCoeffs["X1", "Estimate"]
# get standard error for regressor
std.error <- modelCoeffs["X1", "Std. Error"]
# calculating t-statistic of the coefficient estimates
t_value <- beta.estimate/std.error
# 8.564298
# calculating the p-value of the t-statistics
p_value <- 2*pt(-abs(t_value), df = nrow(sim.data)- 2)
# 3.132848e-11
# f- statistic
f_statistic <- linearMod$fstatistic[1]
# calculating the parameters for model p-value
f<- summary(linearMod)$fstatistic
#   value    numdf    dendf
# 73.3472 1.00000 48.00000
model_p <-  pf(f[1],f[2],f[3], lower =FALSE)
# model p-value
# 3.132848e-11
# Find AIC and BIC
AIC(linearMod)
# 343.659
BIC(linearMod)
# 349.395
# ==============================================================================
# ===== PREDICTING LINEAR MODELS ===============================================
# In this section, we generate a linear model of 80% of our data
# This is then used to predict the other 20% of our data
# First, we create Training Test data
#  set seed to reproduce results of random sampling
set.seed(100)
# row indices for training data
trainingRowIndex <- sample(1:nrow(sim.data), 0.8*nrow(sim.data))
# make training Data
trainingData <- sim.data[trainingRowIndex, ]
# make test Data
testData <- sim.data[-trainingRowIndex, ]
# Build the model on training data
lmMod <- lm(Y~X1, data =trainingData)
# Review diagnostic measures
summary(lmMod)
#> Coefficients:
#> Estimate Std. Error t value Pr(>|t|)
#> (Intercept)  107.395     16.452   6.528 1.08e-07 ***
#>  X1             4.373      0.641   6.823 4.27e-08 ***
#> Residual standard error: 7.813 on 38 degrees of freedom
#> Multiple R-squared:  0.5506,	Adjusted R-squared:  0.5387
#> F-statistic: 46.55 on 1 and 38 DF,  p-value: 4.275e-08
# What does all this tell us?
# both the predictor's and model's p value are less than 0.05
# So we have a statistically significant model
# ==============================================================================
# ==== PREDICTION ACCURACY =====================================================
# use the model of the training data to predict the testData
YPred <- predict(lmMod, testData)
# make a dataframe with the actual and predicted data
actual_preds <- data.frame(cbind(actuals = testData$Y,
predicteds =YPred))
# inspect the actual_preds dataframe
head(actual_preds)
# actuals predicteds
# 3  209.0133   218.9149
# 11 225.9502   226.6082
# 18 204.2498   202.8588
# 19 217.0146   212.8311
# 21 212.0542   214.8210
# 23 206.8188   209.1757
# what is the correlation accuracy of the actual and predicted values
correlation_accuracy <- cor(actual_preds)
# 92.001 %
# calculate min_max accuracy of the model
min_max_accuracy <- mean(apply(actual_preds,1,min)/
apply(actual_preds,1,max))
# 98.31% (the higher the better)
# calculate mean absolute percentage error
mape <- mean(abs((actual_preds$predicteds - actual_preds$actuals))/
actual_preds$ actuals)
# 1.73% , mean absolute percentage deviation (the lower the better)
# ==============================================================================
# ===== K-FOLD CROSS VALIDATION ===============================================
# the R packages needed for this section are lattice and DAAG
# Our previous model performed satisfactorily
# but how can we know it will all the time
# we can rigorously test the model's performance as many times as we please
# This is done using a k-fold cross validation
# for our purposes, we use a 10 fold
# change margins back to normal so the plot fits one window
par(mfrow = c(1,1))
# make plot
cvResults <- suppressWarnings( CVlm (sim.data, form.lm = Y ~ X1,
m=10, dots=FALSE, seed=29,
legend.pos="topleft",  printit=FALSE,
main="10-Fold Cross Validation"))
# supress warning supresses the warnings
# Lines are very close and  parallel
# This confirms the linear model's performance
# find mean squared error of k-fold cross validation
attr(cvResults, 'ms')
# 53.15313 , the lower the better
# ==============================================================================
View(cvResults)
View(cvResults)
# supress warning supresses the warnings
# Lines are very close and  parallel
# This confirms the linear model's performance
write.csv(cvResults, paste(path.results,"cross.validataion.csv", sep = ""),
row.names = FALSE)
View(cvResults)
# write a csv with the actual and predicted values
write.csv(actual_preds, paste(path.results,"predictions.csv", sep = ""),
row.names = FALSE)
# ==== ASSUMPTION 5 ============================================================
# The regressor and the residuals of the linear model are uncorrelated
# We can test this using the cor.test function
cor.test(sim.data$X1, linearMod$residuals)
# check assumptions for our model
gvlma(linearMod)
# check assumptions for our model
assumption.check <-gvlma(linearMod)
View(assumption.check)
#=== COMPARING AIC AND BIC =====================================================
# Calculate the AIC of the simple linear Model
AIC(linearMod)
# Calculate the AIC of the multiple linear model
AIC(mult.mod)
# ------ RUN SCRIPT ------------------------------------------------------------
# for this section, we need the Rpackages AER and MASS
# we also need  to run the linear regression script since we will be comparing
source("3.simple.linear.regression.R")
# if we remember,there was another determinant of Y that was correlated with X1
# check "simulation.R"
# in our orignal model, we put it aside
# let us take it into account in a new model
mult.mod <- lm(Y ~ X1 + X2 , data = sim.data)
# Calculate the AIC of the multiple linear model
AIC(mult.mod)
#
#
#
# DATA ANALYSIS OF DEBT DATA
# Performing Regression Analyses of clean debt data
#
#
# ==== READ CSV ================================================================
debt.data <- read.csv(paste(path.data.clean,"debt.clean.csv",
sep = ""),
stringsAsFactors = FALSE,
strip.white = TRUE, na.strings = "NA")
head(debt.data)
# ==============================================================================
# ====== COUNTRY DATA SUBSETS ================================================
# Create subsets of data according to years
# subset 2009 data
data.2009 <- subset(debt.data,years == "2009")
# subset 2014 data
data.2014 <- subset(debt.data,years == "2014")
#  subset 2019 data
data.2019 <- subset(debt.data,years == "2019")
# ==============================================================================
# ======= DEBT STOCK REGRESSION ================================================
# do a simple linear regression
# plotting debt stock against financial integration
scatter.smooth(x= debt.data$financial.integration,
y= debt.data$debt.stock, main ="Debt stock~ financial integration")
# checking for outliers
par(mfrow = c(1,2))  # diving graph area in 2 columns
# make a box plot for financial integration
boxplot(debt.data$financial.integration, main = "Financial Integration")
# find outliers
boxplot.stats(debt.data$financial.integration)[]
# make vector of outliers
fi.out <- c(17700686746, 32132536118, 36607977032,
56197765491, 18027049171, 10689168577,
33128223077, 53612271731)
# make a box plot for debt stock
boxplot(debt.data$debt.stock, main = "Debt Stock")
# create vector of outliers
ds.out <- boxplot.stats(debt.data$debt.stock)$out
# is the response variable close to normality
# Using density plots
# divide graph area in 2 columns
par(mfrow=c(1,2))
# making a density plot for debt.stock
plot(density(debt.data$debt.stock,na.rm = T), main = "Density Plot: Debt.stock",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$debt.stock, na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$debt.stock, na.rm =T), col = 'red')
# Skewness =  2.69
# This means that the data is positively skewed
# making a density plot for financial integration
plot(density(debt.data$financial.integration,na.rm = T),
main = "Density Plot: Financial.Integration",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$financial.integration,
na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$financial.integration, na.rm =T), col = 'red')
# Skewness =  3.69
# This means that the data is positively skewed
# run a correlation test
cor.test(debt.data$debt.stock,debt.data$financial.integration)
#   cor
# -0.1806223
# The results show no statistically significant correlation
# This correlation is a weak negative correlation
# what happens when we make a linear model of this poorly structured data
debt.mod<- lm(debt.stock ~ financial.integration, data = debt.data,
na.action = na.exclude)
debt.mod
# Coefficients:
# (Intercept)  financial.integration
# 5.462e+01             -7.218e-10
# see if a polynomial fit will be better
debt.mod_2 <- lm(debt.stock ~ financial.integration + I(financial.integration^2),
data = debt.data )
# Coefficients:
# (Intercept)       financial.integration
# 6.166e+01                  -3.668e-09
# I(financial.integration^2)
# 6.294e-20
# let's visualize how well these lines fit the data
# set margins back to normal
par(mfrow = c(1,1))
# let's plot our data
debt.plot<- stripchart(debt.stock ~ financial.integration,
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
debt.plot_2<- stripchart(debt.stock ~ financial.integration + factor(years),
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
# overlay both models on the data
abline(debt.mod)
abline(debt.mod_2)
# Warning message:
# In abline(debt.mod_2) :
#         only using the first two of 3 regression coefficients
# what happens when I take into account the years
mult.debt.mod<- lm(debt.stock ~ factor(years) + financial.integration, data =
debt.data)
# Coefficients:
#         (Intercept)      factor(years)2014      factor(years)2019
# 9.234e+01             -5.922e+01             -4.988e+01
# financial.integration
# -2.608e-10
# since my data did not show correlation, I decided against using it
# there was no real claims I could make given the shortcomings of the dataset
# the sample size was small, and there was a lot of missing data and outliers
# This could also be because the factors I look at,
# have a very low association in real life
# As a result, I decided to move on to a simulated dataset
# This project was to learn how to perform a regression analyses in R
# See subsequent scripts for guidance
# ==============================================================================
# ==== COMPARE MODELS ==========================================================
# All 3 models did not tell us much
# But, let us compare their adjusted R-squared values
# for the simple linear regression model
summary(debt.mod)
# Residual standard error: 41.08 on 80 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.03262,	Adjusted R-squared:  0.02053
# F-statistic: 2.698 on 1 and 80 DF,  p-value: 0.1044
# for the polynomial regression model
summary(debt.mod_2)
# Residual standard error: 40.17 on 79 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.08686,	Adjusted R-squared:  0.06374
# F-statistic: 3.757 on 2 and 79 DF,  p-value: 0.02762
# for the multiple regression model
summary(mult.debt.mod)
# Residual standard error: 33.42 on 78 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.3758,	Adjusted R-squared:  0.3517
# F-statistic: 15.65 on 3 and 78 DF,  p-value: 4.648e-08
# for all 3, the multiple regression model explained the values best
# however, it showed extremely low coefficients
# Thence,there can hardly be any claims on the association of variables
# ==============================================================================
abline(debt.mod_2, col = 'navy')
# Residual standard error: 33.42 on 78 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.3758,	Adjusted R-squared:  0.3517
# F-statistic: 15.65 on 3 and 78 DF,  p-value: 4.648e-08
AIC(mult.debt.mod)
# Residual standard error: 40.17 on 79 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.08686,	Adjusted R-squared:  0.06374
# F-statistic: 3.757 on 2 and 79 DF,  p-value: 0.02762
AIC(debt.mod_2)
# Residual standard error: 41.08 on 80 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.03262,	Adjusted R-squared:  0.02053
# F-statistic: 2.698 on 1 and 80 DF,  p-value: 0.1044
AIC(debt.mod)
# make the folders if they don't exist yet.
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
path.scripts <- paste(wk.dir, "/",folder.names[5], "/", sep = "")
# make the folders if they don't exist yet.
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
path.scripts <- paste(wk.dir, "/",folder.names[5], "/", sep = "")
# names of project folders ("figures", "data.raw","data.clean","results")
# store names of the folders in an object
folder.names <- c("1.data.raw","2.data.clean", "3.results",
"4.figures","5.scripts")
# and make the folders if they don't exit yet. No need to understand this now
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
path.scripts <- paste(wk.dir, "/", folder.names[5], "/", sep = "")
# names of project folders ("figures", "data.raw","data.clean","results")
# store names of the folders in an object
folder.names <- c("1.data.raw","2.data.clean", "3.results","4.figures",
"5.scripts")
# make the folders if they don't exist yet.
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
path.scripts <- paste(wk.dir, "/",folder.names[5], "/", sep = "")
