# ==== MEASURES OF FIT IN MULTIPLE REGRESSION ==================================
# What is the R^2 and Adjusted R^2 of our multiple regression model
# find out with summary
summary(mult.mod)
# Residual standard error: 4.162 on 47 degrees of freedom
# Multiple R-squared:  0.8716,	Adjusted R-squared:  0.8661
# F-statistic: 159.5 on 2 and 47 DF,  p-value: < 2.2e-16
# Let us compare this effect size with that of the single regression model
summary(linearMod)
# Residual standard error: 7.229 on 48 degrees of freedom
# Multiple R-squared:  0.6044,	Adjusted R-squared:  0.5962
# F-statistic: 73.35 on 1 and 48 DF,  p-value: 3.133e-11
# 0.8661 > 0.5962
# The multiple regression model  has a much higher adjusted R-squared
# ==============================================================================
# ==== OLS ASSUMPTIONS IN MULTIPLE REGRESSION ==================================
# The assumptions  of a multiple regression model are similar to that for a
# linear regression, except that of multicollinearity
# Multiple regressions require that no two regressors are perfectly correlated
# In such cases,R does not compute coefficients for the perfectly correlated regressor
# The higher the correlation between regressors, the higher the variance of ..
# ... model coefficient estimates.
# to check the variance inflation, we use the vif function from the DAAG package
vif(mult.mod)
#     X1     X2
# 1.1114 1.1114
# a vif of more than 4 is cause for concern
# for our model, we can see that the regressors are not multicorrelated
# to visualize this relationship, we can use the corrplot function
# this is obtained from the Rpackpage "corrplot"
# we plot the regressors without the response variable
corrplot(cor(sim.data[,-3]))
# from the plot, we see that X1 and X2 are not very correlated
# ==============================================================================
#=== COMPARING AIC AND BIC =====================================================
# Calculate the AIC of the simple linear Model
AIC(linearMod)
# 343.659
# Calculate the AIC of the multiple linear model
AIC(mult.mod)
# 289.4026
# The AIC of the multiple linear model is lesser than than of the simple linear
# model.
# ==============================================================================
# ==== DISTRIBUTION OF OLS ESTIMATES ===========================================
# we need to load the R package "MASS"
# initialize vector of coefficients
coefs <- cbind("hat_beta_1" = numeric(10000), "hat_beta_2" = numeric(10000))
# set seed for reproducibility
set.seed(1)
# loop sampling and estimation of our model
# create a loop that randomly generates numbers
# this will be done in the same way we simulated data
for (i in 1:10000) {
A<- rmvnorm(50, c(25, 50), sigma = cbind(c(5, 1.25), c(1.25, 10)))
e <- rnorm(50, sd = 5)
B <- 5 + 2.5 * A[, 1] + 3 * A[, 2] + e
# store coefficients in vector for coefficients
coefs[i,] <- lm(B ~ A[,1] + A[,2])$coefficients[- 1]
}
# compute density estimates
kde <- kde2d(coefs[,1], coefs[,2])
# plot density estimate
persp(kde,
theta = 30,
phi = 30,
xlab = "beta_1",
ylab = "beta_2",
zlab = "Est. Density",
main = "Distribution of Model Estimates")
# the plot shows a distribution of coefficients estimated by R
# ==============================================================================
# ===== CONCLUSION =============================================================
# Our original simulated data showed a true model of :
# Y = 5 + 2.5 * X[, 1] + 3 * X[, 2] + u
# linearMod estimated that Y= 105.308 + 4.436*X[,1]
# mult.mod estimated that Y = -20.424 + 3.451*X[,1] + 3.009*X[,2]
# These are both attempts to estimate the true model
# we can progress to more complex forms of modeling
# And these might allow for better estimations of the true model
# ==============================================================================
#
#
#
# DATA MANIPULATION
# Retrieving the data I need
#
# ======== RAW DATA ============================================================
# let's read the raw data from data.raw
debt.raw <- read.csv(paste(path.data.raw,"debt.raw.csv",
sep = ""),
stringsAsFactors = FALSE,
strip.white = TRUE)
# inspect the structure of data.raw
str(debt.raw)
head(debt.raw)
# inspect series names
str(debt.raw)
unique(debt.raw$ï..series.name)
# make columns with yearly data numeric
for (i in 5:ncol(debt.raw)){
debt.raw[,i] <- as.numeric(as.character(debt.raw[,i]))
}
# ==============================================================================
# ======== DATA  MANIPULATION ==================================================
# making subsets of data with variables to be used
# use a function
# x represents the unique Series Name
getvar <- function(x){
chosen.var <- subset(debt.raw,ï..series.name == x )
return(chosen.var)
}
# creating data frames of the variables to be used
debt.stock <- getvar("External debt stocks (% of GNI)")
gni <- getvar("GNI (current US$)" )
debt.service.cap <- getvar("Total debt service (% of exports of goods, services and primary income)")
fdi <- getvar("Foreign direct investment, net (BoP, current US$)" )
portfolio <- getvar("Portfolio investment, net (BoP, current US$)")
export <- getvar("Exports of goods and services (current US$)")
import <- getvar("Imports of goods and services (current US$)")
str(export)
# maybe I should create a function that find fi. values for each year
fi <- function(i){
e.val<- export[,i]* 0.25
i.val <- import[,i] * 0.25
fdi.val <- fdi[,i] * 0.3
p.val <- portfolio[,i] * 0.2
fi.val <- e.val + i.val + fdi.val + p.val
return(fi.val)
}
# financial integration values for the years to be compared
fi.2009 <- fi(6)
fi.2014 <- fi(11)
fi.2019 <- fi(16)
# make dataframe with country names and others only
debt.clean <- data.frame(rep(export$Country.Name,3))
# make a vector of years
years <- c(rep(2009, 48),rep(2014,48), rep(2019,48))
# add this vector as a column in debt. clean
debt.clean$years <- years
# add financial integration data
debt.clean$financial.integration <- c(fi.2009,fi.2014, fi.2019)
str(debt.stock)
# retrieve debt stock figures for 2009, 2014, and 2019
ds.2009 <- debt.stock[,6]
ds.2014 <- debt.stock[,11]
ds.2019 <- debt.stock[,16]
# add debt stock data to debt.clean
debt.clean$debt.stock <- c(ds.2009, ds.2014, ds.2019)
# retrieve debt service capabilities figures
dsc.2009 <- debt.service.cap[,6]
dsc.2014 <- debt.service.cap [,11]
dsc.2019 <- debt.service.cap [,16]
# add debt service data to debt.clean
debt.clean$debt.service.cap <- c(dsc.2009,dsc.2014,dsc.2019)
# set column names
colnames(debt.clean) <- c("country.name", "years", "financial.integration",
"debt.stock", "debt.service.cap")
# write debt.clean as a csv in path.data.clean
write.csv(debt.clean, paste(path.data.clean,"debt.clean.csv", sep = ""),
row.names = FALSE)
# make data set that drops data with NA financial integration
debt.new <- debt.clean[complete.cases(debt.clean),]
# write a new csv with complete data
write.csv(debt.new, paste(path.data.clean,"debt.complete.csv", sep = ""),
row.names = FALSE)
# ==============================================================================
#
#
#
# DATA ANALYSIS OF DEBT DATA
# Performing Regression Analyses of clean debt data
#
#
# ==== READ CSV ================================================================
debt.data <- read.csv(paste(path.data.clean,"debt.clean.csv",
sep = ""),
stringsAsFactors = FALSE,
strip.white = TRUE, na.strings = "NA")
head(debt.data)
# ==============================================================================
# ====== COUNTRY DATA SUBSETS ================================================
# Create subsets of data according to years
# subset 2009 data
data.2009 <- subset(debt.data,years == "2009")
# subset 2014 data
data.2014 <- subset(debt.data,years == "2014")
#  subset 2019 data
data.2019 <- subset(debt.data,years == "2019")
# ==============================================================================
# ======= DEBT STOCK REGRESSION ================================================
# do a simple linear regression
# plotting debt stock against financial integration
scatter.smooth(x= debt.data$financial.integration,
y= debt.data$debt.stock, main ="Debt stock~ financial integration")
# checking for outliers
par(mfrow = c(1,2))  # diving graph area in 2 columns
# make a box plot for financial integration
boxplot(debt.data$financial.integration, main = "Financial Integration")
# find outliers
boxplot.stats(debt.data$financial.integration)[]
# make vector of outliers
fi.out <- c(17700686746, 32132536118, 36607977032,
56197765491, 18027049171, 10689168577,
33128223077, 53612271731)
# make a box plot for debt stock
boxplot(debt.data$debt.stock, main = "Debt Stock")
# create vector of outliers
ds.out <- boxplot.stats(debt.data$debt.stock)$out
# is the response variable close to normality
# Using density plots
# divide graph area in 2 columns
par(mfrow=c(1,2))
# making a density plot for debt.stock
plot(density(debt.data$debt.stock,na.rm = T), main = "Density Plot: Debt.stock",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$debt.stock, na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$debt.stock, na.rm =T), col = 'red')
# Skewness =  2.69
# This means that the data is positively skewed
# making a density plot for financial integration
plot(density(debt.data$financial.integration,na.rm = T),
main = "Density Plot: Financial.Integration",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$financial.integration,
na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$financial.integration, na.rm =T), col = 'red')
# Skewness =  3.69
# This means that the data is positively skewed
# run a correlation test
cor.test(debt.data$debt.stock,debt.data$financial.integration)
#   cor
# -0.1806223
# The results show no statistically significant correlation
# This correlation is a weak negative correlation
# what happens when we make a linear model of this poorly structured data
debt.mod<- lm(debt.stock ~ financial.integration, data = debt.data,
na.action = na.exclude)
debt.mod
# Coefficients:
# (Intercept)  financial.integration
# 5.462e+01             -7.218e-10
# see if a polynomial fit will be better
debt.mod_2 <- lm(debt.stock ~ financial.integration + I(financial.integration^2),
data = debt.data )
# Coefficients:
# (Intercept)       financial.integration
# 6.166e+01                  -3.668e-09
# I(financial.integration^2)
# 6.294e-20
# let's visualize how well these lines fit the data
# set margins back to normal
par(mfrow = c(1,1))
# let's plot our data
debt.plot<- stripchart(debt.stock ~ financial.integration,
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
debt.plot_2<- stripchart(debt.stock ~ financial.integration + factor(years),
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
# overlay both models on the data
abline(debt.mod)
abline(debt.mod_2, col = 'navy')
# Warning message:
# In abline(debt.mod_2) :
#         only using the first two of 3 regression coefficients
# what happens when I take into account the years
mult.debt.mod<- lm(debt.stock ~ factor(years) + financial.integration, data =
debt.data)
# Coefficients:
#         (Intercept)      factor(years)2014      factor(years)2019
# 9.234e+01             -5.922e+01             -4.988e+01
# financial.integration
# -2.608e-10
# since my data did not show correlation, I decided against using it
# there was no real claims I could make given the shortcomings of the dataset
# the sample size was small, and there was a lot of missing data and outliers
# This could also be because the factors I look at,
# have a very low association in real life
# As a result, I decided to move on to a simulated dataset
# This project was to learn how to perform a regression analyses in R
# See subsequent scripts for guidance
# ==============================================================================
# ==== COMPARE MODELS ==========================================================
# All 3 models did not tell us much
# But, let us compare their adjusted R-squared values
# for the simple linear regression model
summary(debt.mod)
# Residual standard error: 41.08 on 80 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.03262,	Adjusted R-squared:  0.02053
# F-statistic: 2.698 on 1 and 80 DF,  p-value: 0.1044
AIC(debt.mod)
# 846.0453
# for the polynomial regression model
summary(debt.mod_2)
# Residual standard error: 40.17 on 79 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.08686,	Adjusted R-squared:  0.06374
# F-statistic: 3.757 on 2 and 79 DF,  p-value: 0.02762
AIC(debt.mod_2)
# 843.3143
# for the multiple regression model
summary(mult.debt.mod)
# Residual standard error: 33.42 on 78 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.3758,	Adjusted R-squared:  0.3517
# F-statistic: 15.65 on 3 and 78 DF,  p-value: 4.648e-08
AIC(mult.debt.mod)
# 814.1262
# for all 3, the multiple regression model explained the values best
# however, it showed extremely low coefficients
# Thence,there can hardly be any claims on the association of variables
# ==============================================================================
# Set the working dir to retrace where files should be
# in case the code fails
wk.dir <- getwd() #
library(mvtnorm)
library(e1071)
library(lattice)
library(DAAG)
library(ggplot2)
library(gvlma)
library(AER)
library(MASS)
library(corrplot)
# =============================================================================
# --- folder management ---
# names of project folders ("figures", "data.raw","data.clean","results")
# store names of the folders in an object
folder.names <- c("1.data.raw","2.data.clean", "3.results","4.figures")
# make the folders if they don't exist yet.
for(i in 1:length(folder.names)){
if(file.exists(folder.names[i]) == FALSE){
dir.create(folder.names[i])
}
}
#Store in an object the file path to these folders so we can
# read from them and write to them.
path.data.raw <- paste(wk.dir, "/", folder.names[1], "/", sep = "")
path.data.clean <- paste(wk.dir, "/", folder.names[2], "/", sep = "")
path.results <- paste(wk.dir, "/", folder.names[3], "/", sep = "")
path.fig <- paste(wk.dir, "/",folder.names[4], "/", sep = "")
# =============================================================================
# ==== end =================================================================
#
#
#
# DATA ANALYSIS OF DEBT DATA
# Performing Regression Analyses of clean debt data
#
#
# ==== READ CSV ================================================================
debt.data <- read.csv(paste(path.data.clean,"debt.clean.csv",
sep = ""),
stringsAsFactors = FALSE,
strip.white = TRUE, na.strings = "NA")
head(debt.data)
# ==============================================================================
# ====== COUNTRY DATA SUBSETS ================================================
# Create subsets of data according to years
# subset 2009 data
data.2009 <- subset(debt.data,years == "2009")
# subset 2014 data
data.2014 <- subset(debt.data,years == "2014")
#  subset 2019 data
data.2019 <- subset(debt.data,years == "2019")
# ==============================================================================
# ======= DEBT STOCK REGRESSION ================================================
# do a simple linear regression
# plotting debt stock against financial integration
scatter.smooth(x= debt.data$financial.integration,
y= debt.data$debt.stock, main ="Debt stock~ financial integration")
# checking for outliers
par(mfrow = c(1,2))  # diving graph area in 2 columns
# make a box plot for financial integration
boxplot(debt.data$financial.integration, main = "Financial Integration")
# find outliers
boxplot.stats(debt.data$financial.integration)[]
# make vector of outliers
fi.out <- c(17700686746, 32132536118, 36607977032,
56197765491, 18027049171, 10689168577,
33128223077, 53612271731)
# make a box plot for debt stock
boxplot(debt.data$debt.stock, main = "Debt Stock")
# create vector of outliers
ds.out <- boxplot.stats(debt.data$debt.stock)$out
# is the response variable close to normality
# Using density plots
# divide graph area in 2 columns
par(mfrow=c(1,2))
# making a density plot for debt.stock
plot(density(debt.data$debt.stock,na.rm = T), main = "Density Plot: Debt.stock",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$debt.stock, na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$debt.stock, na.rm =T), col = 'red')
# Skewness =  2.69
# This means that the data is positively skewed
# making a density plot for financial integration
plot(density(debt.data$financial.integration,na.rm = T),
main = "Density Plot: Financial.Integration",
ylab = "Frequency",
sub = paste("Skewness:",round(e1071::skewness(debt.data$financial.integration,
na.rm = T),2)))
# making the polygon red
polygon(density(debt.data$financial.integration, na.rm =T), col = 'red')
# Skewness =  3.69
# This means that the data is positively skewed
# run a correlation test
cor.test(debt.data$debt.stock,debt.data$financial.integration)
#   cor
# -0.1806223
# The results show no statistically significant correlation
# This correlation is a weak negative correlation
# what happens when we make a linear model of this poorly structured data
debt.mod<- lm(debt.stock ~ financial.integration, data = debt.data,
na.action = na.exclude)
debt.mod
# Coefficients:
# (Intercept)  financial.integration
# 5.462e+01             -7.218e-10
# see if a polynomial fit will be better
debt.mod_2 <- lm(debt.stock ~ financial.integration + I(financial.integration^2),
data = debt.data )
# Coefficients:
# (Intercept)       financial.integration
# 6.166e+01                  -3.668e-09
# I(financial.integration^2)
# 6.294e-20
# let's visualize how well these lines fit the data
# set margins back to normal
par(mfrow = c(1,1))
# let's plot our data
debt.plot<- stripchart(debt.stock ~ financial.integration,
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
debt.plot_2<- stripchart(debt.stock ~ financial.integration + factor(years),
data =debt.data,
vertical = TRUE,
pch = 16,
cex = 1.5, las = 1, col = "firebrick",
xlab = "Financial Integration", ylab = "Debt Stock",
main = "Debt stock ~ Financial Integration")
# overlay both models on the data
abline(debt.mod)
abline(debt.mod_2, col = 'navy')
# Warning message:
# In abline(debt.mod_2) :
#         only using the first two of 3 regression coefficients
# what happens when I take into account the years
mult.debt.mod<- lm(debt.stock ~ factor(years) + financial.integration, data =
debt.data)
# Coefficients:
#         (Intercept)      factor(years)2014      factor(years)2019
# 9.234e+01             -5.922e+01             -4.988e+01
# financial.integration
# -2.608e-10
# since my data did not show correlation, I decided against using it
# there was no real claims I could make given the shortcomings of the dataset
# the sample size was small, and there was a lot of missing data and outliers
# This could also be because the factors I look at,
# have a very low association in real life
# As a result, I decided to move on to a simulated dataset
# This project was to learn how to perform a regression analyses in R
# See subsequent scripts for guidance
# ==============================================================================
# ==== COMPARE MODELS ==========================================================
# All 3 models did not tell us much
# But, let us compare their adjusted R-squared values
# for the simple linear regression model
summary(debt.mod)
# Residual standard error: 41.08 on 80 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.03262,	Adjusted R-squared:  0.02053
# F-statistic: 2.698 on 1 and 80 DF,  p-value: 0.1044
AIC(debt.mod)
# 846.0453
# for the polynomial regression model
summary(debt.mod_2)
# Residual standard error: 40.17 on 79 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.08686,	Adjusted R-squared:  0.06374
# F-statistic: 3.757 on 2 and 79 DF,  p-value: 0.02762
AIC(debt.mod_2)
# 843.3143
# for the multiple regression model
summary(mult.debt.mod)
# Residual standard error: 33.42 on 78 degrees of freedom
# (62 observations deleted due to missingness)
# Multiple R-squared:  0.3758,	Adjusted R-squared:  0.3517
# F-statistic: 15.65 on 3 and 78 DF,  p-value: 4.648e-08
AIC(mult.debt.mod)
# 814.1262
# for all 3, the multiple regression model explained the values best
# however, it showed extremely low coefficients
# Thence,there can hardly be any claims on the association of variables
# ==============================================================================
